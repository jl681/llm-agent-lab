{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab073a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Qwen API Key å·²åŠ è½½\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 1. åŠ è½½ API Keys                             â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "QWEN_API_KEY = os.getenv(\"QWEN_API_KEY\")\n",
    "if not QWEN_API_KEY:\n",
    "    raise ValueError(\"âŒ è¯·é…ç½® QWEN_API_KEY\")\n",
    "\n",
    "print(\"âœ… Qwen API Key å·²åŠ è½½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a9c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 2. å®‰è£…å¿…è¦åº“                                â”‚\n",
    "# â”‚ ï¼ˆä»…ç”¨äº PDF/æ–‡æœ¬å¤„ç†ï¼‰                      â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# !pip install PyPDF2 sentence-transformers numpy scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82230ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š çŸ¥è¯†åº“ chunks:\n",
      "  0: é˜¿é‡Œå·´å·´é›†å›¢æˆç«‹äº1999å¹´ï¼Œæ€»éƒ¨ä½äºä¸­å›½æ­å·ã€‚\n",
      "  1: é€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ˜¯é˜¿é‡Œå·´å·´æ¨å‡ºçš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œå¤šç§è¯­è¨€ã€‚\n",
      "  2: é˜¿é‡Œäº‘æ˜¯å…¨çƒçŸ¥åçš„äº‘è®¡ç®—åŠäººå·¥æ™ºèƒ½ç§‘æŠ€å…¬å¸ï¼Œæä¾›å¼¹æ€§è®¡ç®—ã€æ•°æ®åº“ã€å®‰å…¨ç­‰æœåŠ¡ã€‚\n",
      "  3: 2024å¹´ï¼Œé˜¿é‡Œå·´å·´å‘å¸ƒäº†Qwen2å’ŒQwen-Maxæ¨¡å‹ï¼Œæ€§èƒ½å¤§å¹…æå‡ã€‚\n",
      "  4: é˜¿é‡Œå·´å·´çš„ä½¿å‘½æ˜¯è®©å¤©ä¸‹æ²¡æœ‰éš¾åšçš„ç”Ÿæ„ã€‚\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 3. åˆ›å»ºç¤ºä¾‹çŸ¥è¯†åº“                            â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "knowledge_base = [\n",
    "    \"é˜¿é‡Œå·´å·´é›†å›¢æˆç«‹äº1999å¹´ï¼Œæ€»éƒ¨ä½äºä¸­å›½æ­å·ã€‚\",\n",
    "    \"é€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ˜¯é˜¿é‡Œå·´å·´æ¨å‡ºçš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œå¤šç§è¯­è¨€ã€‚\",\n",
    "    \"é˜¿é‡Œäº‘æ˜¯å…¨çƒçŸ¥åçš„äº‘è®¡ç®—åŠäººå·¥æ™ºèƒ½ç§‘æŠ€å…¬å¸ï¼Œæä¾›å¼¹æ€§è®¡ç®—ã€æ•°æ®åº“ã€å®‰å…¨ç­‰æœåŠ¡ã€‚\",\n",
    "    \"2024å¹´ï¼Œé˜¿é‡Œå·´å·´å‘å¸ƒäº†Qwen2å’ŒQwen-Maxæ¨¡å‹ï¼Œæ€§èƒ½å¤§å¹…æå‡ã€‚\",\n",
    "    \"é˜¿é‡Œå·´å·´çš„ä½¿å‘½æ˜¯è®©å¤©ä¸‹æ²¡æœ‰éš¾åšçš„ç”Ÿæ„ã€‚\"\n",
    "]\n",
    "\n",
    "# åˆ†å—ï¼ˆè¿™é‡Œæ¯å¥å·²æ˜¯ä¸€ä¸ª chunkï¼‰\n",
    "chunks = knowledge_core = knowledge_base\n",
    "print(\"ğŸ“š çŸ¥è¯†åº“ chunks:\")\n",
    "for i, c in enumerate(chunks):\n",
    "    print(f\"  {i}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae912779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”Ÿæˆ 5 ä¸ª chunk çš„ embedding\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 4. è°ƒç”¨ Qwen Embedding æ¨¡å‹                   â”‚\n",
    "# â”‚ æ³¨æ„ï¼šDashScope å…¼å®¹ OpenAI çš„ embeddings æ¥å£  |\n",
    "# â”‚ åœ¨guidesä¸‹æœ‰Embeddingsç®€å•ä»‹ç»ã€‚                â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "embedding_client = OpenAI(\n",
    "    api_key=QWEN_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    response = embedding_client.embeddings.create(\n",
    "        model=\"text-embedding-v2\",  # é˜¿é‡Œäº‘ embedding æ¨¡å‹å\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# ä¸ºæ‰€æœ‰ chunks ç”Ÿæˆ embeddingï¼ˆå®é™…åº”ç”¨ä¸­åº”ç¼“å­˜ï¼ï¼‰\n",
    "chunk_embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "print(f\"âœ… å·²ç”Ÿæˆ {len(chunk_embeddings)} ä¸ª chunk çš„ embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec47a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æŸ¥è¯¢: Qwen æ˜¯å“ªå®¶å…¬å¸å‘å¸ƒçš„ï¼Ÿ\n",
      "ğŸ“„ æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µ:\n",
      "  â€¢ 2024å¹´ï¼Œé˜¿é‡Œå·´å·´å‘å¸ƒäº†Qwen2å’ŒQwen-Maxæ¨¡å‹ï¼Œæ€§èƒ½å¤§å¹…æå‡ã€‚\n",
      "  â€¢ é€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ˜¯é˜¿é‡Œå·´å·´æ¨å‡ºçš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œå¤šç§è¯­è¨€ã€‚\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 5. ç›¸ä¼¼æ€§æ£€ç´¢                                â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "def retrieve(query: str, top_k: int = 2) -> list[str]:\n",
    "    query_emb = np.array(get_embedding(query)).reshape(1, -1)\n",
    "    chunk_embs = np.array(chunk_embeddings)\n",
    "    \n",
    "    similarities = cosine_similarity(query_emb, chunk_embs)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    return [chunks[i] for i in top_indices]\n",
    "\n",
    "# æµ‹è¯•æ£€ç´¢\n",
    "query = \"Qwen æ˜¯å“ªå®¶å…¬å¸å‘å¸ƒçš„ï¼Ÿ\"\n",
    "retrieved = retrieve(query)\n",
    "print(f\"ğŸ” æŸ¥è¯¢: {query}\")\n",
    "print(\"ğŸ“„ æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µ:\")\n",
    "for r in retrieved:\n",
    "    print(f\"  â€¢ {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "645f173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ é—®é¢˜: Qwen æ˜¯å“ªå®¶å…¬å¸å‘å¸ƒçš„ï¼Ÿ\n",
      "ğŸ¤– å›ç­”: Qwen æ˜¯ç”±é˜¿é‡Œå·´å·´å‘å¸ƒçš„ã€‚\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 6. ç”Ÿæˆæœ€ç»ˆå›ç­”                              â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "llm_client = OpenAI(\n",
    "    api_key=QWEN_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "def rag_answer(question: str) -> str:\n",
    "    # 1. æ£€ç´¢\n",
    "    docs = retrieve(question, top_k=2)\n",
    "    context = \"\\n\".join(docs)\n",
    "    \n",
    "    # 2. æ„é€  prompt\n",
    "    prompt = f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªå‡†ç¡®ã€å¯é çš„ä¿¡æ¯åŠ©æ‰‹ã€‚\n",
    "è¯·**ä¸¥æ ¼åŸºäºä»¥ä¸‹æä¾›çš„èµ„æ–™**å›ç­”é—®é¢˜ï¼Œä¸è¦ç¼–é€ ã€‚\n",
    "\n",
    "èµ„æ–™ï¼š\n",
    "{context}\n",
    "\n",
    "é—®é¢˜ï¼š{question}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    # 3. è°ƒç”¨ LLM\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"qwen-max\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1  # é™ä½éšæœºæ€§ï¼Œæé«˜äº‹å®æ€§\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# æµ‹è¯•\n",
    "question = \"Qwen æ˜¯å“ªå®¶å…¬å¸å‘å¸ƒçš„ï¼Ÿ\"\n",
    "answer = rag_answer(question)\n",
    "print(f\"â“ é—®é¢˜: {question}\")\n",
    "print(f\"ğŸ¤– å›ç­”: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a284b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å¯¹æ¯”å®éªŒï¼š\n",
      "é—®é¢˜: é˜¿é‡Œå·´å·´æˆç«‹äºå“ªä¸€å¹´ï¼Ÿ\n",
      "\n",
      "âŒ æ—  RAGï¼ˆå¯èƒ½å¹»è§‰ï¼‰:\n",
      "é˜¿é‡Œå·´å·´é›†å›¢æˆç«‹äº1999å¹´ã€‚\n",
      "\n",
      "âœ… æœ‰ RAGï¼ˆåŸºäºçŸ¥è¯†åº“ï¼‰:\n",
      "é˜¿é‡Œå·´å·´é›†å›¢æˆç«‹äº1999å¹´ã€‚\n"
     ]
    }
   ],
   "source": [
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚ 7. å¯¹æ¯”å®éªŒ                                  â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "def direct_answer(question: str) -> str:\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"qwen-max\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "question = \"é˜¿é‡Œå·´å·´æˆç«‹äºå“ªä¸€å¹´ï¼Ÿ\"\n",
    "\n",
    "print(\"ğŸ§ª å¯¹æ¯”å®éªŒï¼š\")\n",
    "print(f\"é—®é¢˜: {question}\\n\")\n",
    "\n",
    "print(\"âŒ æ—  RAGï¼ˆå¯èƒ½å¹»è§‰ï¼‰:\")\n",
    "print(direct_answer(question))\n",
    "\n",
    "print(\"\\nâœ… æœ‰ RAGï¼ˆåŸºäºçŸ¥è¯†åº“ï¼‰:\")\n",
    "print(rag_answer(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
