{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5cbc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Qwen API Key 已成功加载！\n"
     ]
    }
   ],
   "source": [
    "# ╭──────────────────────────────────────╮\n",
    "# │ 1. 加载 API Key（来自 .env 文件）     │\n",
    "# ╰──────────────────────────────────────╯\n",
    "# ✅ 提示：.env 应包含 QWEN_API_KEY=sk-xxx\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载 .env 文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "QWEN_API_KEY = os.getenv(\"QWEN_API_KEY\")\n",
    "\n",
    "if not QWEN_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"❌ 未找到 QWEN_API_KEY！\\n\"\n",
    "        \"请确保：\\n\"\n",
    "        \"1. 已创建 .env 文件（参考 .env.example）\\n\"\n",
    "        \"2. 已从阿里云百炼控制台获取 API Key\\n\"\n",
    "        \"3. Jupyter 是在激活虚拟环境后启动的\"\n",
    "    )\n",
    "\n",
    "print(\"✅ Qwen API Key 已成功加载！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d5ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ openai 版本: 2.16.0\n"
     ]
    }
   ],
   "source": [
    "# ╭──────────────────────────────────────╮\n",
    "# │ 2. 确保已安装 openai SDK             │\n",
    "# ╰──────────────────────────────────────╯\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "except ImportError:\n",
    "    print(\"正在安装 openai...\")\n",
    "    %pip install openai -q\n",
    "\n",
    "# 验证版本（需 >= 1.0）\n",
    "import openai\n",
    "print(f\"✅ openai 版本: {openai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db917eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Qwen 回答：\n",
      "通义千问是阿里云自主研发的超大规模语言模型，能够帮助用户生成各类文本，如文章、故事、诗歌、故事等，并支持多轮对话和代码写作等功能。\n"
     ]
    }
   ],
   "source": [
    "# ╭──────────────────────────────────────────────────────╮\n",
    "# │ 3. 调用 Qwen（通过 OpenAI 兼容接口）                 │\n",
    "# │    这是未来支持多模型（Qwen/Doubao/OpenAI）的基础 │\n",
    "# ╰──────────────────────────────────────────────────────╯\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# 初始化客户端：base_url 指向 DashScope 的 OpenAI 兼容端点\n",
    "client = OpenAI(\n",
    "    api_key=QWEN_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "def ask_qwen(prompt: str, model: str = \"qwen-max\") -> str:\n",
    "    \"\"\"\n",
    "    向 Qwen 发送请求并返回回答\n",
    "    支持模型：qwen-max, qwen-plus, qwen-turbo 等\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# 测试调用\n",
    "response = ask_qwen(\"你好！请用一句话介绍通义千问。\")\n",
    "print(\"🤖 Qwen 回答：\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ed8be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 测试模型: qwen-turbo\n",
      "⏱️  耗时: 3.01s\n",
      "💬 回答: 好的！我们用一个小学生能听懂的话来解释什么是大语言模型（LLM）。\n",
      "\n",
      "---\n",
      "\n",
      "**大语言模型（LLM）就像是一个超级聪明的“知识小助手”，它会说话、会写故事、会回答问题，甚至还能讲笑话。**\n",
      "\n",
      "这个“小助手”不是真人，而是一个**电脑程序**。它被训练得非常厉害，因为它看过很多很多书、文章、对话，...\n",
      "\n",
      "🔍 测试模型: qwen-plus\n",
      "⏱️  耗时: 9.32s\n",
      "💬 回答: 当然可以！😊\n",
      "\n",
      "你可以把**大语言模型（LLM）** 想象成一个“超级爱读书、记性特别好、还会讲故事和聊天的机器人朋友”！\n",
      "\n",
      "📚 它读过**超级多的书、网页、文章、故事、诗歌、笑话……**（就像把整个图书馆+互联网都“吃”进脑子里啦！），所以它知道很多词怎么用、句子怎么说、事情是怎么回事。\n",
      "\n",
      "🧠 它...\n",
      "\n",
      "🔍 测试模型: qwen-max\n",
      "⏱️  耗时: 8.51s\n",
      "💬 回答: 大语言模型就像是一个超级聪明的“故事书”，但它不是普通的书，而是一个可以和你聊天、回答问题、甚至帮你写故事的神奇“故事书”。想象一下，如果你有一个朋友，他读过世界上几乎所有的书，知道很多很多的事情，而且还能用这些知识来帮助你完成作业、解答疑惑，甚至一起创作新的故事。这个超级聪明的朋友就是大语言模型的...\n"
     ]
    }
   ],
   "source": [
    "# ╭──────────────────────────────────────╮\n",
    "# │ 4. 对比不同 Qwen 模型的响应速度与质量 │\n",
    "# ╰──────────────────────────────────────╯\n",
    "\n",
    "import time\n",
    "\n",
    "models = [\"qwen-turbo\", \"qwen-plus\", \"qwen-max\"]\n",
    "prompt = \"解释什么是大语言模型（LLM），用小学生能懂的话。\"\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n🔍 测试模型: {model}\")\n",
    "    start = time.time()\n",
    "    try:\n",
    "        answer = ask_qwen(prompt, model=model)\n",
    "        latency = time.time() - start\n",
    "        print(f\"⏱️  耗时: {latency:.2f}s\")\n",
    "        print(f\"💬 回答: {answer[:150]}...\")  # 截断显示\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 调用失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╭──────────────────────────────────────╮\n",
    "# │ 5. 总结                              │\n",
    "# ╰──────────────────────────────────────╯\n",
    "\n",
    "print(\"🎉 恭喜！你已完成：\")\n",
    "print(\"✅ 从阿里云百炼获取 Qwen API Key\")\n",
    "print(\"✅ 通过 OpenAI 兼容接口调用 Qwen\")\n",
    "print(\"✅ 测试了多个 Qwen 模型\")\n",
    "\n",
    "print(\"\\n➡️ 下一步：我们将封装一个统一的 LLM 接口，\")\n",
    "print(\"   让你的代码同时支持 Qwen、豆包（Doubao）、OpenAI！\")\n",
    "\n",
    "print(\"\\n📚 提示：详细获取 API Key 的步骤见：\")\n",
    "print(\"   guides/如何获取大模型API KEY： 以通义千问为例.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
